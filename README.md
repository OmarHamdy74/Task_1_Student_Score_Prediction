
---

# ğŸ¯ Exam Score Prediction using Linear & Polynomial Regression

![Python](https://img.shields.io/badge/Python-3.x-blue)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“Œ Overview
This project demonstrates **data analysis** and **predictive modeling** for **exam scores** using:
- âœ… **Exploratory Data Analysis (EDA)**
- âœ… **Handling Missing Values**
- âœ… **Feature Engineering**
- âœ… **Linear Regression and Polynomial Regression**
- âœ… **Model Evaluation (RÂ², MAE, RMSE)**

The implementation is done in **Python** using **Jupyter Notebook**.

---

## ğŸ“‚ Project Structure
```

StudentPerformanceFactors.ipynb    # Main Jupyter Notebook with analysis and model
requirements.txt                   # List of required Python packages
README.md                          # Project documentation

````

---

## ğŸ”§ Requirements
Install dependencies using:
```bash
pip install -r requirements.txt
````

**Main libraries:**

* pandas
* numpy
* matplotlib
* seaborn
* missingno
* scikit-learn

---

## ğŸš€ Features

* ğŸ“Š Data cleaning and visualization using **pandas**, **seaborn**, and **missingno**
* â• Polynomial feature generation using `PolynomialFeatures`
* ğŸ” Model training using **LinearRegression**
* âœ… Performance evaluation:

  * **RÂ² Score**
  * **Mean Absolute Error (MAE)**
  * **Root Mean Squared Error (RMSE)**

---

## ğŸ“Š Evaluation Metrics

The project reports:

* **RÂ² Score**: Measures how well the model explains variance
* **MAE**: Average absolute error
* **RMSE**: Penalizes larger errors

---

## â–¶ï¸ How to Run

1. **Clone this repository:**

   ```bash
   git clone https://github.com/OmarHamdy74/Task_1_Student_Score_Prediction.git
   ```
2. **Navigate to the project directory:**

   ```bash
   cd exam-score-prediction
   ```
3. **Install requirements:**

   ```bash
   pip install -r requirements.txt
   ```
4. **Open the notebook:**

   ```bash
   jupyter notebook StudentPerformanceFactors.ipynb
   ```

---

## ğŸ“ˆ Future Improvements

* ğŸ”¹ Use **regularization (Ridge, Lasso)** to avoid overfitting
* ğŸ”¹ Add **Cross-validation**
* ğŸ”¹ Try **different models** like Decision Trees or Random Forest

---

## ğŸ›  Author

Developed by **Omar Hamdy**
ğŸ’¼ Data Analysis & Machine Learning Enthusiast
ğŸ“§ Email: [omarhamdy211@gmail.com](mailto:omarhamdy211@gmail.com)
ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/omar-hamdy-400961253/)

---

```

